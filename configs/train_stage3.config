# =============================================================================
# Stage 3 Configuration - Training Optimizations
# =============================================================================
# Stage: 1 + 2 + 3
# Max Length: L=1024-1536
# Memory: ~8GB for L=1024 (with FP16)
# Memory Saving: 8-16x (loss) + 50% (FP16)
# Speed Improvement: 2-3x (FP16 + optimizations)
# Use Case: Efficient training with progressive curriculum
# =============================================================================

# Basic Training Settings
name stage3_optimized_training
seed 42
batchSize 2
gradientAccumulation 2
maximumNumResidues 1024

# Model Architecture
singleFeatureDimension 256
pairFeatureDimension 128
structureEncoderDepth 3
structureEncoderHeads 4

# *** STAGE 1: Factorized Pairs ***
useFactorizedPairs True
zFactorRank 2
pairFactorDim 64

# *** STAGE 2: Factorized Triangle Ops ***
useFactorizedTriangleOps True
triangleUpdateRank 4
triangleAttentionChunkSize 256
numTriangleLayers 4

# *** STAGE 3 KEY FEATURES: Training Optimizations ***
# Progressive Training: Curriculum from short to long
useProgressiveTraining True
progressiveStartLength 128      # Start with short sequences
progressiveEndLength 1024       # End with target length
progressiveNumStages 4          # Number of curriculum stages
progressiveEpochsPerStage 50    # Epochs per stage

# Chunked Loss: Compute loss in chunks to save memory
useChunkedLoss True
lossChunkSize 256              # Process 256 residues at a time

# Mixed Precision: FP16 for speed and memory
useMixedPrecision True
precision 16                   # Use FP16 (BF16 if available)
gradScaler True                # Gradient scaling for stability

# Learning Rate & Optimization
learningRate 2e-4
warmupEpochs 100
numEpochs 500
gradientClipVal 1.0
weightDecay 0.01

# Loss Settings with mHC Loss
lossWeights {
    "translation": 1.0,
    "rotation": 1.0,
    "backbone": 1.0,
    "chi": 0.5,
    "mhc": 0.1              # Multi-scale Hierarchical Consistency
}

# mHC Loss Settings
useMHCLoss True
mhcNumScales 3              # Multi-scale: 3 levels
mhcWeights [0.5, 0.3, 0.2]  # Weights for each scale

# Diffusion Settings
diffusionTimesteps 1000
diffusionSchedule cosine
noiseSchedule exponential

# Hardware Settings
numWorkers 4
accelerator gpu
devices 1

# Monitoring
logEveryNSteps 50
saveEveryNEpochs 10
validateEveryNEpochs 5

# Stage Features
useSparseKNN False
useAxialAttention False
useModelCompression False
useDistributed False
