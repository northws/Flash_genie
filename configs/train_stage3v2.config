# =============================================================================
# Stage 3 V2 Configuration - Sparse k-NN Pairs
# =============================================================================
# Stage: 1 + 2 + 3 + V2
# Max Length: L=4096-6144
# Memory: ~18GB for L=4096 (k=32)
# Memory Saving: 128-256x (sparse pairs)
# Use Case: Ultra-long sequence training with sparse interactions
# =============================================================================

# Basic Training Settings
name stage3v2_sparse_training
seed 42
batchSize 1
gradientAccumulation 4
maximumNumResidues 4096

# Model Architecture
singleFeatureDimension 128      # Reduced for memory
pairFeatureDimension 128
structureEncoderDepth 3
structureEncoderHeads 4

# *** STAGE 1: Factorized Pairs ***
useFactorizedPairs True
zFactorRank 2
pairFactorDim 64

# *** STAGE 2: Factorized Triangle Ops ***
useFactorizedTriangleOps True
triangleUpdateRank 4
triangleAttentionChunkSize 256
numTriangleLayers 4

# *** STAGE 3: Training Optimizations ***
useProgressiveTraining True
progressiveStartLength 512
progressiveEndLength 4096
progressiveNumStages 5
progressiveEpochsPerStage 50

useChunkedLoss True
lossChunkSize 512

useMixedPrecision True
precision 16

# *** STAGE 3 V2 KEY FEATURE: Sparse k-NN Pairs ***
useSparseKNN True
kNeighbors 32                   # Keep only 32 nearest neighbors per residue
knnStrategy hybrid              # Options: coordinate, sequence, hybrid
knnUpdateFrequency 10           # Update k-NN graph every N steps

# Spatial locality bias
useSpatialBias True
spatialBiasRange 16             # Bias toward local interactions

# Learning Rate & Optimization
learningRate 2e-4
warmupEpochs 100
numEpochs 500
gradientClipVal 1.0
weightDecay 0.01

# Loss Settings
lossWeights {
    "translation": 1.0,
    "rotation": 1.0,
    "backbone": 1.0,
    "chi": 0.5,
    "mhc": 0.1
}

useMHCLoss True
mhcNumScales 3
mhcWeights [0.5, 0.3, 0.2]

# Diffusion Settings
diffusionTimesteps 1000
diffusionSchedule cosine
noiseSchedule exponential

# Hardware Settings
numWorkers 4
accelerator gpu
devices 1

# Monitoring
logEveryNSteps 50
saveEveryNEpochs 10
validateEveryNEpochs 5

# Stage Features
useAxialAttention False
useModelCompression False
useDistributed False
